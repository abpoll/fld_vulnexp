{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3033b7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T16:19:44.557722Z",
     "start_time": "2023-08-23T16:19:44.526884Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7682daa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T16:20:14.470723Z",
     "start_time": "2023-08-23T16:19:46.151856Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import zipfile_deflate64\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import glob\n",
    "from os.path import join\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "from pyproj import CRS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff387690",
   "metadata": {},
   "source": [
    "# Configure files and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ca48fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T16:20:22.977373Z",
     "start_time": "2023-08-23T16:20:22.124154Z"
    }
   },
   "outputs": [],
   "source": [
    "# It could make sense to have a lib/ style directory\n",
    "# like PLACES has for common functionality\n",
    "# and this code block would be useful there for getting\n",
    "# a fr() path\n",
    "\n",
    "# Filepath directories\n",
    "\n",
    "# Get the absolute path to the project directory\n",
    "# Which is one directory above notebooks/\n",
    "ABS_DIR = os.path.abspath(Path(os.getcwd()).parents[0])\n",
    "# Get raw data directory\n",
    "FR = join(ABS_DIR, 'data', 'raw')\n",
    "# Get interim data directory\n",
    "FI = join(ABS_DIR, 'data', 'interim')\n",
    "# Get processed data directory\n",
    "FP = join(ABS_DIR, 'data', 'processed')\n",
    "\n",
    "# Directories for raw exposure, vulnerability (vuln) and \n",
    "# administrative reference files\n",
    "#  all exist so just need references\n",
    "EXP_DIR_R = join(FR, 'exposure')\n",
    "VULN_DIR_R = join(FR, 'vuln')\n",
    "REF_DIR_R = join(FR, 'ref')\n",
    "# Haz is for FEMA NFHL and depth grids\n",
    "HAZ_DIR_R = join(FR, 'haz')\n",
    "\n",
    "# Directories for interim exposure, vulnerability (vuln) and \n",
    "# hazard\n",
    "EXP_DIR_I = join(FI, 'exposure')\n",
    "VULN_DIR_I = join(FI, 'vuln')\n",
    "HAZ_DIR_I = join(FI, 'haz')\n",
    "\n",
    "# Ensure they exist\n",
    "Path(EXP_DIR_I).mkdir(parents=True, exist_ok=True)\n",
    "Path(VULN_DIR_I).mkdir(parents=True, exist_ok=True)\n",
    "Path(HAZ_DIR_I).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6f226",
   "metadata": {},
   "source": [
    "# Unzip and move files to interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932542b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:32:16.763360Z",
     "start_time": "2023-08-22T21:31:26.237921Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each .zip directory in fr\n",
    "# Create needed subdirectories in interim/\n",
    "# Unzip in the appropriate interim/ subdirectory\n",
    "\n",
    "for path in Path(FR).rglob('*.zip'):\n",
    "    # Avoid hidden files and files in directories\n",
    "    if path.name[0] != '.':\n",
    "        # Get root for the directory this .zip file is in\n",
    "        zip_root = path.relative_to(FR).parents[0]\n",
    "\n",
    "        # Get path to interim/zip_root\n",
    "        zip_to_path = join(FI, zip_root)\n",
    "\n",
    "        # Make directory, including parents\n",
    "        # No need to check if directory exists bc\n",
    "        # it is only created when this script is run\n",
    "        Path(zip_to_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Unzip to zip_to_path\n",
    "        with ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(zip_to_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73059",
   "metadata": {},
   "source": [
    "# Reproject and clip spatial data to location boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b56dc1a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:40:46.599778Z",
     "start_time": "2023-08-22T21:40:45.833564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reference the city limits clip file\n",
    "boundary_filep = join(REF_DIR_R, 'city.gpkg')\n",
    "# Read boundary\n",
    "boundary = gpd.read_file(boundary_filep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fccfa0",
   "metadata": {},
   "source": [
    "## NSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e65785f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:49:14.867818Z",
     "start_time": "2023-08-22T21:49:11.641693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read raw NSI data\n",
    "nsi_filep = join(EXP_DIR_R, 'nsi.pqt')\n",
    "# Read and reset index\n",
    "nsi_full = pd.read_parquet(nsi_filep).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f430ee79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:49:29.983810Z",
     "start_time": "2023-08-22T21:49:29.370721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to geodataframe\n",
    "geometry = gpd.points_from_xy(nsi_full['properties.x'],\n",
    "                             nsi_full['properties.y'])\n",
    "# The NSI CRS is EPSG 4326\n",
    "nsi_gdf_f = gpd.GeoDataFrame(nsi_full, geometry=geometry,\n",
    "                             crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f91add8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:50:37.688919Z",
     "start_time": "2023-08-22T21:50:19.481191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Project nsi_gdf_f coordinates so that they\n",
    "# match the boundary CRS\n",
    "nsi_gdf_f = nsi_gdf_f.to_crs(boundary.crs)\n",
    "\n",
    "# Use spatial join to get nsi locations within location boundary\n",
    "# Note: this does not remove any properties for this case study\n",
    "# but can if you change the boundary file, which is a feature\n",
    "# that should be available to future users\n",
    "nsi_gdf = gpd.sjoin(nsi_gdf_f, boundary[['geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b900919a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:51:39.014509Z",
     "start_time": "2023-08-22T21:51:38.327848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the following columns\n",
    "drop_cols = ['type', 'geometry.type', 'geometry.coordinates', 'index_right']\n",
    "nsi_gdf = nsi_gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in nsi_gdf.columns]\n",
    "nsi_gdf.columns = col_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7061423c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:54:55.507123Z",
     "start_time": "2023-08-22T21:52:50.150285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the NSI data to interim\n",
    "nsi_gdf.to_file(join(EXP_DIR_I, 'nsi.gpkg'), driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551244d",
   "metadata": {},
   "source": [
    "## Depth Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54bc5d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T23:39:00.430421Z",
     "start_time": "2023-08-22T22:54:46.391673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning proccessing: CstDpth0_2pct.tif\n",
      "CstDpth0_2pct.tif reprojected and clipped\n",
      "Beginning proccessing: CstDpth01pct.tif\n",
      "CstDpth01pct.tif reprojected and clipped\n",
      "Beginning proccessing: CstDpth02pct.tif\n",
      "CstDpth02pct.tif reprojected and clipped\n",
      "Beginning proccessing: CstDpth10pct.tif\n",
      "CstDpth10pct.tif reprojected and clipped\n",
      "Beginning proccessing: Depth_0_2pct.tif\n",
      "Depth_0_2pct.tif reprojected and clipped\n",
      "Beginning proccessing: Depth_01pct.tif\n",
      "Depth_01pct.tif reprojected and clipped\n",
      "Beginning proccessing: Depth_02pct.tif\n",
      "Depth_02pct.tif reprojected and clipped\n",
      "Beginning proccessing: Depth_10pct.tif\n",
      "Depth_10pct.tif reprojected and clipped\n"
     ]
    }
   ],
   "source": [
    "# There are depth and coastal depth grids\n",
    "# We want each one reprojected and clipped to the area boundary\n",
    "# In general, I think it makes more sense to extract the depths from\n",
    "# the raster in its original CRS, but for plotting purposes it can be\n",
    "# useful to have all data in a standardized CRS. I think this should match\n",
    "# up with the CRS of the boundary, but there could be better CRS to choose\n",
    "\n",
    "# List of depth grid filenames\n",
    "dg_names = ['CstDpth0_2pct.tif', 'CstDpth01pct.tif',\n",
    "            'CstDpth02pct.tif', 'CstDpth10pct.tif',\n",
    "            'Depth_0_2pct.tif', 'Depth_01pct.tif',\n",
    "            'Depth_02pct.tif', 'Depth_10pct.tif']\n",
    "\n",
    "# List of out filenames\n",
    "dg_names_out = ['cst_depth500.tif', 'cst_depth100.tif',\n",
    "                'cst_depth50.tif', 'cst_depth10.tif',\n",
    "                'in_depth500.tif', 'in_depth100.tif',\n",
    "                'in_depth50.tif', 'in_depth10.tif']\n",
    "# Interim directory\n",
    "dg_in_dir = join(HAZ_DIR_I, 'dg')\n",
    "# Out directory (same as in, but it's nice to have\n",
    "# different name references for logic in the script)\n",
    "dg_out_dir = join(HAZ_DIR_I, 'dg')\n",
    "Path(dg_out_dir).mkdir(parents=True, exist_ok=True)\n",
    "# Temp directory (for reprojected)\n",
    "dg_tmp_dir = join(HAZ_DIR_I, 'tmp')\n",
    "Path(dg_tmp_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Store crs\n",
    "DST_CRS = boundary.crs\n",
    "\n",
    "# Loop through each, reproject, write in interim\n",
    "# TODO: I expect you always have to reproject, but\n",
    "# it's better practice to check if the CRS are equal\n",
    "for i, dg_in in enumerate(dg_names):\n",
    "    print('Beginning proccessing: ' + dg_in)\n",
    "    \n",
    "    # In, tmp, out filepaths\n",
    "    dg_in_filep = join(dg_in_dir, dg_in)\n",
    "    # Reprojected files go in tmp, so replace . with _r.\n",
    "    dg_tmp_filep = join(dg_tmp_dir, dg_in.replace('.', '_r.'))\n",
    "    # In/out filepaths line up, so can use the i for index\n",
    "    dg_out_filep = join(dg_out_dir, dg_names_out[i])\n",
    "    \n",
    "    # reprojecting grid to match boundary crs\n",
    "    # Following rasterio references\n",
    "    # https://rasterio.readthedocs.io/en/stable/topics/reproject.html\n",
    "    with rasterio.open(dg_in_filep) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, DST_CRS, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': DST_CRS,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(dg_tmp_filep, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=DST_CRS,\n",
    "                    resampling=Resampling.nearest)\n",
    "\n",
    "    # Clip depth grid to boundary using mark\n",
    "    # https://rasterio.readthedocs.io/en/stable/\n",
    "    # topics/masking-by-shapefile.html\n",
    "    with rasterio.open(dg_tmp_filep) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src,\n",
    "                                                      boundary['geometry'],\n",
    "                                                      crop=True)\n",
    "        out_meta = src.meta\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "\n",
    "    with rasterio.open(dg_out_filep, \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "        \n",
    "    # TODO: makes sense to include a log for checking bottlenecks\n",
    "    # Can write out how long it took to do the reprojection & clipping\n",
    "    # For now, since running in jupyter, just printing out\n",
    "    print(dg_in + ' reprojected and clipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c805d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the original and new rasters to each other to see what you did\n",
    "# Double check that these steps are necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d301f",
   "metadata": {},
   "source": [
    "## Flood Zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056014e",
   "metadata": {},
   "source": [
    "## SOVI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d1748",
   "metadata": {},
   "source": [
    "# Link ref data to tabular data if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7437bd",
   "metadata": {},
   "source": [
    "## BGs to LMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d477a88d",
   "metadata": {},
   "source": [
    "## NFIP claims/pols to tracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589912f",
   "metadata": {},
   "source": [
    "# Parcel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa4744",
   "metadata": {},
   "source": [
    "## Clean and filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b44da",
   "metadata": {},
   "source": [
    "## Join with building footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f15c105",
   "metadata": {},
   "source": [
    "## Merge with hazard and social vuln data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a92d05",
   "metadata": {},
   "source": [
    "# Prepare depth-damage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e00469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icom_risk",
   "language": "python",
   "name": "icom_risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
