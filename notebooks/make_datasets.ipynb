{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3033b7e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T14:28:48.815374Z",
     "start_time": "2023-08-28T14:28:48.252903Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7682daa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T14:29:16.717651Z",
     "start_time": "2023-08-28T14:28:48.819893Z"
    }
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import zipfile_deflate64\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import glob\n",
    "from os.path import join\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio.mask\n",
    "from pyproj import CRS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff387690",
   "metadata": {},
   "source": [
    "# Configure files and other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ca48fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T14:29:17.265334Z",
     "start_time": "2023-08-28T14:29:16.725618Z"
    }
   },
   "outputs": [],
   "source": [
    "# It could make sense to have a lib/ style directory\n",
    "# like PLACES has for common functionality\n",
    "# and this code block would be useful there for getting\n",
    "# a fr() path\n",
    "\n",
    "# Filepath directories\n",
    "\n",
    "# Get the absolute path to the project directory\n",
    "# Which is one directory above notebooks/\n",
    "ABS_DIR = os.path.abspath(Path(os.getcwd()).parents[0])\n",
    "# Get raw data directory\n",
    "FR = join(ABS_DIR, 'data', 'raw')\n",
    "# Get interim data directory\n",
    "FI = join(ABS_DIR, 'data', 'interim')\n",
    "# Get processed data directory\n",
    "FP = join(ABS_DIR, 'data', 'processed')\n",
    "\n",
    "# Directories for raw exposure, vulnerability (vuln) and \n",
    "# administrative reference files\n",
    "#  all exist so just need references\n",
    "EXP_DIR_R = join(FR, 'exposure')\n",
    "VULN_DIR_R = join(FR, 'vuln')\n",
    "REF_DIR_R = join(FR, 'ref')\n",
    "# Haz is for FEMA NFHL and depth grids\n",
    "HAZ_DIR_R = join(FR, 'haz')\n",
    "\n",
    "# Directories for interim exposure, vulnerability (vuln) and \n",
    "# hazard\n",
    "EXP_DIR_I = join(FI, 'exposure')\n",
    "VULN_DIR_I = join(FI, 'vuln')\n",
    "HAZ_DIR_I = join(FI, 'haz')\n",
    "\n",
    "# Ensure they exist\n",
    "Path(EXP_DIR_I).mkdir(parents=True, exist_ok=True)\n",
    "Path(VULN_DIR_I).mkdir(parents=True, exist_ok=True)\n",
    "Path(HAZ_DIR_I).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Reference fips\n",
    "FIPS = '42101'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6f226",
   "metadata": {},
   "source": [
    "# Unzip and move files to interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932542b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:32:16.763360Z",
     "start_time": "2023-08-22T21:31:26.237921Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each .zip directory in fr\n",
    "# Create needed subdirectories in interim/\n",
    "# Unzip in the appropriate interim/ subdirectory\n",
    "\n",
    "for path in Path(FR).rglob('*.zip'):\n",
    "    # Avoid hidden files and files in directories\n",
    "    if path.name[0] != '.':\n",
    "        # Get root for the directory this .zip file is in\n",
    "        zip_root = path.relative_to(FR).parents[0]\n",
    "\n",
    "        # Get path to interim/zip_root\n",
    "        zip_to_path = join(FI, zip_root)\n",
    "\n",
    "        # Make directory, including parents\n",
    "        # No need to check if directory exists bc\n",
    "        # it is only created when this script is run\n",
    "        Path(zip_to_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Unzip to zip_to_path\n",
    "        with ZipFile(path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(zip_to_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67db191",
   "metadata": {},
   "source": [
    "# Obtain base data for structure inventories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8988746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T17:23:21.647614Z",
     "start_time": "2023-08-23T17:23:20.602752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parcels are the core exposure element \n",
    "# of building-based flood risk assessments\n",
    "# This can be represented by appraisal or NSI data\n",
    "\n",
    "# First, we want to clean and filter the parcel dataset for\n",
    "# the information we need for our flood risk assessment\n",
    "# Then, we want to link parcels with all of the other information\n",
    "# that we will use in our flood risk assessment\n",
    "# This includes attribute links and spatial links\n",
    "# for things like footprints, flood hazard, administrative references\n",
    "\n",
    "# We want to link parcels to other spatial features in the\n",
    "# CRS of those spatial features. This will limit \n",
    "# expensive spatial processing for tasks like reprojection. For example,\n",
    "# if we were to reproject every flood hazard depth grid to the\n",
    "# parcel CRS, we would need to perform many redundant reprojection tasks.\n",
    "# Instead, we could reproject the parcels one time and overlay this with\n",
    "# all the depth grids. A downside of this approach is that if we want to\n",
    "# plot depth grids and parcels, we would likely want to do this in \n",
    "# the parcel CRS. Since plotting is an occassional task, but linking\n",
    "# parcels & depths is a ubiquitous one, I think it's better to do the\n",
    "# parcel reprojection for spatial merges. There are also layers that will\n",
    "# share the CRS of the parcels since WGS84 is very common for parcel\n",
    "# datasets, reference files like block groups, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100cbb1a",
   "metadata": {},
   "source": [
    "## Process NSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9722cc9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T17:44:49.815706Z",
     "start_time": "2023-08-23T17:44:48.759721Z"
    }
   },
   "outputs": [],
   "source": [
    "# The NSI comes with all the data necessary for performing a standard \n",
    "# flood risk assessment. It is still useful to process the raw data.\n",
    "# Here, we subset to residential properties with 1 to 2 stories\n",
    "# and save as a geodataframe. These are the types of residences we have\n",
    "# multiple depth-damage functions for and a literature base to draw \n",
    "# from to introduce uncertainty in these loss estimates\n",
    "\n",
    "# We are going to use the following occupancy types \n",
    "# RES1 - single family residences\n",
    "# Res2 - manufactured home\n",
    "# RES 3 - multifamily residences\n",
    "# Only if they have <= 2 stories (we lack info for specing \n",
    "# the kinds of DDFs we'd like to -- w/ uncertainty -- for 3 story houses)\n",
    "# RES2 \n",
    "# While DDFs are not specific to manufactured homes, as long\n",
    "# as we know basement type, foundation height, and\n",
    "# stories, we can use the requisite DDF archetype\n",
    "\n",
    "# Future versions of this framework will not subset to the residential\n",
    "# properties as done here, but since we don't have the \n",
    "# requisite depth-damage function information for other properties,\n",
    "# it would be a waste of storage space and processing time to \n",
    "# save/process a larger NSI .gpkg file at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56792e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T18:08:49.450731Z",
     "start_time": "2023-08-23T18:08:47.736047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read raw NSI data\n",
    "nsi_filep = join(EXP_DIR_R, 'nsi.pqt')\n",
    "# Read and reset index\n",
    "nsi_full = pd.read_parquet(nsi_filep).reset_index(drop=True)\n",
    "\n",
    "# Convert to geodataframe\n",
    "geometry = gpd.points_from_xy(nsi_full['properties.x'],\n",
    "                             nsi_full['properties.y'])\n",
    "# The NSI CRS is EPSG 4326\n",
    "nsi_gdf = gpd.GeoDataFrame(nsi_full, geometry=geometry,\n",
    "                           crs=\"EPSG:4326\")\n",
    "\n",
    "# Drop the following columns\n",
    "drop_cols = ['type', 'geometry.type', 'geometry.coordinates']\n",
    "nsi_gdf = nsi_gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in nsi_gdf.columns]\n",
    "nsi_gdf.columns = col_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f7c4358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T18:16:26.747506Z",
     "start_time": "2023-08-23T18:16:26.228788Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset to residential properties and update\n",
    "# RES 1 - single family\n",
    "# RES 2 - manufactured home\n",
    "# RES 3 - multifamily (but could fit into a depth-damage function\n",
    "# archetype depending on # stories)\n",
    "\n",
    "# occtype category for easier use in loss estimation steps\n",
    "\n",
    "# Get residential structures\n",
    "nsi_res = nsi_gdf.loc[nsi_gdf['st_damcat'] == 'RES']\n",
    "\n",
    "\n",
    "# Add #story and wb (with basement) or nb (no basement) to RES3 homes\n",
    "# Store NB or WB indexed to RES3 homes based on B,C and N found_type\n",
    "# Get num_story + 'S' \n",
    "# Merge these and then add to occtype for RES3 homes\n",
    "\n",
    "# Start with index of res3 homes\n",
    "res3_ind = nsi_res['occtype'].str[:4] == 'RES3'\n",
    "# Get subsetted df\n",
    "res3 = nsi_res.loc[res3_ind]\n",
    "\n",
    "# For this subset\n",
    "# If found_type == B, then WB\n",
    "# Else then NB\n",
    "res3b = np.where(res3['found_type'] == 'B',\n",
    "                 'WB',\n",
    "                 'NB')\n",
    "# For this subset\n",
    "# Get num_story + 'S'\n",
    "res3s = res3['num_story'].astype(str) + 'S'\n",
    "\n",
    "# Adjust occtype column for these homes in nsi_res\n",
    "nsi_res.loc[res3_ind, 'occtype'] = res3['occtype'] + '-' + res3s + res3b\n",
    "\n",
    "# For this case-study, don't use any building with more \n",
    "# than 2 stories\n",
    "res1_3s_ind = nsi_res['num_story'] > 2\n",
    "# Final residential dataframe\n",
    "res_f = nsi_res.loc[~res1_3s_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "815c4f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T18:31:03.442356Z",
     "start_time": "2023-08-23T18:29:25.950916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset to relevant columns\n",
    "cols = ['fd_id', 'occtype', 'found_type', 'cbfips',\n",
    "        'ftprntsrc', 'found_ht', 'val_struct',\n",
    "        'val_cont', 'source', 'firmzone', 'ground_elv_m',\n",
    "        'geometry']\n",
    "\n",
    "res_out = res_f.loc[:,cols]\n",
    "\n",
    "# Write out to interim/exposure/\n",
    "EXP_OUT_FILEP = join(EXP_DIR_I, 'nsi_res.gpkg')\n",
    "nsi_res.to_file(EXP_OUT_FILEP, driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ad3ca",
   "metadata": {},
   "source": [
    "## Process appraiser data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "495d38f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:04:12.363649Z",
     "start_time": "2023-08-28T18:02:24.204087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load philadelphia water department parcels\n",
    "pc_pwd = gpd.read_file(join(EXP_DIR_R, 'pc_pwd.gpkg'))\n",
    "\n",
    "# Load philadelphia office of property assessment parcels\n",
    "pc_opa = gpd.read_file(join(EXP_DIR_R, 'pc_opa.gpkg'))\n",
    "\n",
    "# Load building footprint data\n",
    "bld_fp = gpd.read_file(join(EXP_DIR_R, 'bld_fp.gpkg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "efaaec69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:14:18.014845Z",
     "start_time": "2023-08-28T18:14:16.453139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove \"properties.\" from the pc_pwd column names\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in pc_pwd.columns]\n",
    "pc_pwd.columns = col_updates\n",
    "\n",
    "# Retain relevant columns\n",
    "col_keep = ['ADDRESS', 'PARCELID',\n",
    "            'PIN', 'BRT_ID', 'geometry']\n",
    "pc_pwd = pc_pwd.loc[:, col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e2793bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:14:18.113388Z",
     "start_time": "2023-08-28T18:14:18.017921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove \"properties.\" from the bld_fp column names\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in bld_fp.columns]\n",
    "bld_fp.columns = col_updates\n",
    "\n",
    "# Retain relevant columns\n",
    "col_keep = ['BIN', 'ADDRESS', 'BASE_ELEVATION',\n",
    "            'PARCEL_ID_NUM', 'Shape__Area', 'geometry']\n",
    "bld_fp = bld_fp.loc[:, col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43898f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T22:55:01.773098Z",
     "start_time": "2023-08-24T22:55:01.755155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter pc_opa and retain relevant columns\n",
    "# Reference https://metadata.phila.gov/#home/datasetdetails/\n",
    "# 5543865f20583086178c4ee5/representationdetails/55d624fdad35c7e854cb21a4/\n",
    "\n",
    "# assessment_date: important for understanding the potential\n",
    "# for renovations/improvements/degradation\n",
    "\n",
    "# basements: detailed fields can be aggregated for whether a building\n",
    "# has a basement or not. whether it is finished or not does not matter\n",
    "# for flood risk estimation other than the effect it may have on \n",
    "# structure value - this is an \"observed\" field with a different column\n",
    "\n",
    "# category_code: identify residential properties. subset to these\n",
    "# 1 - single family, 2 - multi family,\n",
    "# 3 - mixed used, 14 - apartments > 4 units\n",
    "\n",
    "# market_value: certified market value (includes land and buildings)\n",
    "\n",
    "# market_value_date: important for getting market value in \n",
    "# correct real value, but it is fully null. so we will use\n",
    "# assessment_date as a proxy for this. \n",
    "\n",
    "# number_stories: # stories above ground level\n",
    "\n",
    "# parcel_number: matches brt_id in PWD parcels\n",
    "\n",
    "# year_built: useful for determining which building codes\n",
    "# construction was subject to\n",
    "\n",
    "# year_built_estimate: indicates if the year_built column is an estimate\n",
    "\n",
    "# pin: use to link to PIN in PWD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f8d1c691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:12:07.466931Z",
     "start_time": "2023-08-28T18:12:05.568175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessment_date</th>\n",
       "      <th>basements</th>\n",
       "      <th>beginning_point</th>\n",
       "      <th>book_and_page</th>\n",
       "      <th>building_code</th>\n",
       "      <th>building_code_description</th>\n",
       "      <th>category_code</th>\n",
       "      <th>category_code_description</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>central_air</th>\n",
       "      <th>...</th>\n",
       "      <th>view_type</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_built_estimate</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>zoning</th>\n",
       "      <th>pin</th>\n",
       "      <th>building_code_new</th>\n",
       "      <th>building_code_description_new</th>\n",
       "      <th>objectid</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>173'1 3/4\" W OF 25TH</td>\n",
       "      <td>None</td>\n",
       "      <td>O30</td>\n",
       "      <td>ROW 2 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>169</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1915</td>\n",
       "      <td>Y</td>\n",
       "      <td>19132</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001071884</td>\n",
       "      <td>22</td>\n",
       "      <td>ROW TYPICAL</td>\n",
       "      <td>356223223</td>\n",
       "      <td>POINT (-75.17417 39.99128)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>D</td>\n",
       "      <td>69'11 1/2\" N OF</td>\n",
       "      <td>None</td>\n",
       "      <td>V10</td>\n",
       "      <td>PRIV GAR 1 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>160</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1899</td>\n",
       "      <td>Y</td>\n",
       "      <td>19125</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001129558</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>356223175</td>\n",
       "      <td>POINT (-75.12713 39.97713)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>SWC VAUX ST</td>\n",
       "      <td>None</td>\n",
       "      <td>C58</td>\n",
       "      <td>DET W/D GAR 3 STY STONE</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>207</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1925</td>\n",
       "      <td>Y</td>\n",
       "      <td>19129</td>\n",
       "      <td>SPINS</td>\n",
       "      <td>1001475014</td>\n",
       "      <td>09</td>\n",
       "      <td>None</td>\n",
       "      <td>356223260</td>\n",
       "      <td>POINT (-75.19365 40.01801)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>336'3 7/8\" N LEB ANON</td>\n",
       "      <td>None</td>\n",
       "      <td>R30</td>\n",
       "      <td>ROW B/GAR 2 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>118</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1940</td>\n",
       "      <td>Y</td>\n",
       "      <td>19131</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001364309</td>\n",
       "      <td>24</td>\n",
       "      <td>ROW PORCH FRONT</td>\n",
       "      <td>356223269</td>\n",
       "      <td>POINT (-75.23999 39.98647)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>D</td>\n",
       "      <td>84' W OF 18TH ST</td>\n",
       "      <td>None</td>\n",
       "      <td>O50</td>\n",
       "      <td>ROW 3 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>134</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>1920</td>\n",
       "      <td>Y</td>\n",
       "      <td>19130</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001392027</td>\n",
       "      <td>22</td>\n",
       "      <td>ROW TYPICAL</td>\n",
       "      <td>356223343</td>\n",
       "      <td>POINT (-75.16749 39.96674)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582630</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>195' W 49TH ST</td>\n",
       "      <td>0000000</td>\n",
       "      <td>H50</td>\n",
       "      <td>SEMI/DET 3 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>86</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1915</td>\n",
       "      <td>None</td>\n",
       "      <td>19139</td>\n",
       "      <td>RSA3</td>\n",
       "      <td>1001132450</td>\n",
       "      <td>36</td>\n",
       "      <td>TWIN OLD STYLE</td>\n",
       "      <td>356794447</td>\n",
       "      <td>POINT (-75.22051 39.95585)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582631</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>947'1 7/8\"NE PEARSON</td>\n",
       "      <td>0000000</td>\n",
       "      <td>K31</td>\n",
       "      <td>S/D W/B GAR 2 STY MAS+OTH</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>348</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>19114</td>\n",
       "      <td>RSA3</td>\n",
       "      <td>1001405432</td>\n",
       "      <td>27</td>\n",
       "      <td>TWIN POST WAR</td>\n",
       "      <td>356794670</td>\n",
       "      <td>POINT (-75.00369 40.06339)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582632</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>308'W OF 60TH ST</td>\n",
       "      <td>0000000</td>\n",
       "      <td>O30</td>\n",
       "      <td>ROW 2 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>82</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1925</td>\n",
       "      <td>None</td>\n",
       "      <td>19143</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001315787</td>\n",
       "      <td>24</td>\n",
       "      <td>ROW PORCH FRONT</td>\n",
       "      <td>356794671</td>\n",
       "      <td>POINT (-75.24543 39.94592)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582633</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>84'3\"W OF 3RD ST</td>\n",
       "      <td>0000000</td>\n",
       "      <td>O50</td>\n",
       "      <td>ROW 3 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1910</td>\n",
       "      <td>Y</td>\n",
       "      <td>19147</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001210715</td>\n",
       "      <td>22</td>\n",
       "      <td>ROW TYPICAL</td>\n",
       "      <td>356794672</td>\n",
       "      <td>POINT (-75.14992 39.93292)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582634</th>\n",
       "      <td>2022-05-24T00:00:00Z</td>\n",
       "      <td>F</td>\n",
       "      <td>205' W 62ND</td>\n",
       "      <td>0000000</td>\n",
       "      <td>R30</td>\n",
       "      <td>ROW B/GAR 2 STY MASONRY</td>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>83</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>I</td>\n",
       "      <td>1925</td>\n",
       "      <td>Y</td>\n",
       "      <td>19139</td>\n",
       "      <td>RM1</td>\n",
       "      <td>1001338675</td>\n",
       "      <td>24</td>\n",
       "      <td>ROW PORCH FRONT</td>\n",
       "      <td>356794673</td>\n",
       "      <td>POINT (-75.24577 39.96160)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463634 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             assessment_date basements        beginning_point book_and_page  \\\n",
       "42      2022-05-24T00:00:00Z      None   173'1 3/4\" W OF 25TH          None   \n",
       "58      2022-05-24T00:00:00Z         D        69'11 1/2\" N OF          None   \n",
       "112     2022-05-24T00:00:00Z      None            SWC VAUX ST          None   \n",
       "121     2022-05-24T00:00:00Z      None  336'3 7/8\" N LEB ANON          None   \n",
       "196     2022-05-24T00:00:00Z         D       84' W OF 18TH ST          None   \n",
       "...                      ...       ...                    ...           ...   \n",
       "582630  2022-05-24T00:00:00Z      None         195' W 49TH ST       0000000   \n",
       "582631  2022-05-24T00:00:00Z      None   947'1 7/8\"NE PEARSON       0000000   \n",
       "582632  2022-05-24T00:00:00Z      None       308'W OF 60TH ST       0000000   \n",
       "582633  2022-05-24T00:00:00Z      None       84'3\"W OF 3RD ST       0000000   \n",
       "582634  2022-05-24T00:00:00Z         F            205' W 62ND       0000000   \n",
       "\n",
       "       building_code  building_code_description category_code  \\\n",
       "42             O30            ROW 2 STY MASONRY            1    \n",
       "58             V10       PRIV GAR 1 STY MASONRY            1    \n",
       "112            C58      DET W/D GAR 3 STY STONE            1    \n",
       "121            R30      ROW B/GAR 2 STY MASONRY            1    \n",
       "196            O50            ROW 3 STY MASONRY            1    \n",
       "...              ...                        ...           ...   \n",
       "582630         H50       SEMI/DET 3 STY MASONRY            1    \n",
       "582631         K31    S/D W/B GAR 2 STY MAS+OTH            1    \n",
       "582632         O30            ROW 2 STY MASONRY            1    \n",
       "582633         O50            ROW 3 STY MASONRY            1    \n",
       "582634         R30      ROW B/GAR 2 STY MASONRY            1    \n",
       "\n",
       "       category_code_description census_tract central_air  ... view_type  \\\n",
       "42                 SINGLE FAMILY          169        None  ...         I   \n",
       "58                 SINGLE FAMILY          160        None  ...         I   \n",
       "112                SINGLE FAMILY          207        None  ...         I   \n",
       "121                SINGLE FAMILY          118        None  ...         I   \n",
       "196                SINGLE FAMILY          134        None  ...         A   \n",
       "...                          ...          ...         ...  ...       ...   \n",
       "582630             SINGLE FAMILY          86         None  ...         I   \n",
       "582631             SINGLE FAMILY          348        None  ...      None   \n",
       "582632             SINGLE FAMILY          82         None  ...         I   \n",
       "582633             SINGLE FAMILY          25         None  ...         I   \n",
       "582634             SINGLE FAMILY          83         None  ...         I   \n",
       "\n",
       "       year_built  year_built_estimate  zip_code  zoning         pin  \\\n",
       "42           1915                    Y     19132    RSA5  1001071884   \n",
       "58           1899                    Y     19125    RSA5  1001129558   \n",
       "112          1925                    Y     19129   SPINS  1001475014   \n",
       "121          1940                    Y     19131    RSA5  1001364309   \n",
       "196          1920                    Y     19130    RSA5  1001392027   \n",
       "...           ...                  ...       ...     ...         ...   \n",
       "582630       1915                 None     19139    RSA3  1001132450   \n",
       "582631       0                    None     19114    RSA3  1001405432   \n",
       "582632       1925                 None     19143    RSA5  1001315787   \n",
       "582633       1910                    Y     19147    RSA5  1001210715   \n",
       "582634       1925                    Y     19139     RM1  1001338675   \n",
       "\n",
       "        building_code_new  building_code_description_new   objectid  \\\n",
       "42                     22                    ROW TYPICAL  356223223   \n",
       "58                   None                           None  356223175   \n",
       "112                    09                           None  356223260   \n",
       "121                    24                ROW PORCH FRONT  356223269   \n",
       "196                    22                    ROW TYPICAL  356223343   \n",
       "...                   ...                            ...        ...   \n",
       "582630                 36                 TWIN OLD STYLE  356794447   \n",
       "582631                 27                  TWIN POST WAR  356794670   \n",
       "582632                 24                ROW PORCH FRONT  356794671   \n",
       "582633                 22                    ROW TYPICAL  356794672   \n",
       "582634                 24                ROW PORCH FRONT  356794673   \n",
       "\n",
       "                          geometry  \n",
       "42      POINT (-75.17417 39.99128)  \n",
       "58      POINT (-75.12713 39.97713)  \n",
       "112     POINT (-75.19365 40.01801)  \n",
       "121     POINT (-75.23999 39.98647)  \n",
       "196     POINT (-75.16749 39.96674)  \n",
       "...                            ...  \n",
       "582630  POINT (-75.22051 39.95585)  \n",
       "582631  POINT (-75.00369 40.06339)  \n",
       "582632  POINT (-75.24543 39.94592)  \n",
       "582633  POINT (-75.14992 39.93292)  \n",
       "582634  POINT (-75.24577 39.96160)  \n",
       "\n",
       "[463634 rows x 79 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO\n",
    "# Print out building_code_description as csv\n",
    "# Review each description value and map it to occupancy codes\n",
    "# from the NSI, (for now, ignoring other useful information that \n",
    "# can be extracted)\n",
    "# The point of this is to get as precise an estimate as possible\n",
    "# of the residential building stock for which we can estimate\n",
    "# flood losses for. This helps us understand\n",
    "# how well the NSI can capture the loss distribution w/ the standard\n",
    "# no uncertainty approach and when uncertainty is included \n",
    "# (but not including uncertainty in sample size because how do you do that?)\n",
    "# Category_code is not the field that provides the best estimate\n",
    "# of the sample we need. Part of the problem is that you end up with\n",
    "# properties you can't link to the PWD/bld_fp data\n",
    "# Using building_code_description filters will put us in a better\n",
    "# position to make these links. After you get this sample\n",
    "# and link it with PWD/bld_fp using the ID column, you can then\n",
    "# use the point data from the OPA parcels that aren't matched\n",
    "# and do spatial joins with the PWD parcel polygon (and the bld_fp)\n",
    "# to ensure that we are making the correct links\n",
    "# We can also do bld_fp centroid in PWD parcel to see if we\n",
    "# are maintaining the same links they provide us with - and get any extra\n",
    "# Lots of ways to do QA to make sure we get the right sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7a8714a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:38:41.238767Z",
     "start_time": "2023-08-28T18:38:37.537935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number OPA Properties: 582635\n",
      "Retained Properties in category codes 1, 2, 3, and 14: 521277\n",
      "Retained Properties with 1 or 2 Stories: 437893\n",
      "Retained Properties with non-zero or non-null market values: 437893\n",
      "Retained Properties with non-null assessment date: 435389\n"
     ]
    }
   ],
   "source": [
    "# Remove \"properties.\" from the pc_opa column names\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in pc_opa.columns]\n",
    "pc_opa.columns = col_updates\n",
    "\n",
    "# How many observations do we start with\n",
    "print('Number OPA Properties: ' + str(len(pc_opa)))\n",
    "\n",
    "# Filter pc_opa to category codes 1, 2, 3, and 14\n",
    "cat_codes = ['1', '2', '3', '14']\n",
    "pc_opa_f = pc_opa.loc[pc_opa['category_code'].str.strip().isin(cat_codes)]\n",
    "\n",
    "print('Retained Properties in category codes 1, 2, 3, and 14: ' \n",
    "      + str(len(pc_opa_f)))\n",
    "\n",
    "# Filter to number stories 1 or 2\n",
    "# FLAG: should we take the assessor data at face value?\n",
    "pc_opa_f = pc_opa_f.loc[(pc_opa_f['number_stories'] == 1) |\n",
    "                        (pc_opa_f['number_stories'] == 2)]\n",
    "\n",
    "print('Retained Properties with 1 or 2 Stories: ' \n",
    "      + str(len(pc_opa_f)))\n",
    "\n",
    "# Keep properties with non-zero and non-null market values\n",
    "pc_opa_f = pc_opa_f.loc[(pc_opa_f['market_value'].notnull())\n",
    "                        & (pc_opa_f['market_value'] != 0)]\n",
    "\n",
    "# Retain relevant columns\n",
    "keep_cols = ['assessment_date', 'category_code',\n",
    "             'market_value', 'number_stories',\n",
    "             'basements', 'building_code_description',\n",
    "              'zoning',\n",
    "             'year_built', 'year_built_estimate',\n",
    "             'parcel_number', 'pin', 'geometry']\n",
    "pc_opa_f = pc_opa_f.loc[:, keep_cols]\n",
    "\n",
    "# How many observations do we filter to\n",
    "print('Retained Properties with non-zero or non-null market values: ' \n",
    "      + str(len(pc_opa_f)))\n",
    "\n",
    "# Retain properties with an assessment date \n",
    "pc_opa_f = pc_opa_f[pc_opa_f['assessment_date'].notnull()]\n",
    "print('Retained Properties with non-null assessment date: ' \n",
    "      + str(len(pc_opa_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "696a6cc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:39:03.613502Z",
     "start_time": "2023-08-28T18:38:45.296040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get year of assessment date\n",
    "# Have to split the string to use pd.to_datetime successfully\n",
    "dates = pd.to_datetime(pc_opa_f['assessment_date'].str.split(' ').str[0],\n",
    "                       format=\"%Y-%m-%d\")\n",
    "years = dates.dt.year\n",
    "\n",
    "# Use the column name \"Year\" to match with the hpi data\n",
    "# for better syntax on merge\n",
    "pc_opa_f = pc_opa_f.assign(Year = years)\n",
    "\n",
    "# Deflate market values in terms of 2022 value\n",
    "# For assessments in 2022, no adjustment needed\n",
    "\n",
    "# Read hpi deflator data\n",
    "hpi_path = join(EXP_DIR_R, 'hpi_county.xlsx')\n",
    "# Manual inspection of file provides the values \n",
    "# for skiprows, HPI as float, FIPS as str\n",
    "hpi = pd.read_excel(hpi_path, skiprows=6, dtype={'FIPS code': 'str'})\n",
    "\n",
    "# Subset to our county\n",
    "hpi_fips = hpi.loc[hpi['FIPS code'] == FIPS]\n",
    "\n",
    "# I can't do dtype 'HPI': 'float' but we need to convert the column\n",
    "# and the below works fine\n",
    "hpi_fips = hpi_fips.assign(hpi=hpi_fips['HPI'].astype(float))\n",
    "\n",
    "# Get HPI with 2022 base\n",
    "# TODO: Define in cfg file\n",
    "YR_BASE = 2022\n",
    "\n",
    "# Do this by dividing HPI values by the HPI value \n",
    "# for the row with Year = 2022\n",
    "# Round to hundredth place\n",
    "# TODO: better column name than hpi_2022 (hpi_base?)\n",
    "base_hpi = hpi_fips.loc[hpi_fips['Year'] == YR_BASE, 'hpi'].values[0]\n",
    "rounded_hpi = round(hpi_fips.loc[:, 'hpi']/base_hpi, 2)\n",
    "hpi_fips = hpi_fips.assign(hpi_2022=round(hpi_fips['hpi']/base_hpi, 2))\n",
    "\n",
    "# Merge the ratio with the parcel dataframe\n",
    "# TODO: it could make sense to add FIPS as a merge\n",
    "# when expanding to more locations\n",
    "# I like changing df names after merges because\n",
    "# if you need to rerun a code block it will work without\n",
    "# column name or index issues\n",
    "pc_opa_f2 = pc_opa_f.merge(hpi_fips[['Year', 'hpi_2022']],\n",
    "                           on='Year',\n",
    "                           how='left')\n",
    "\n",
    "# Making the assumption that assessments in 2023 have \n",
    "# similar value to those from 2022, otherwise we get null entries\n",
    "pc_opa_f2.loc[pc_opa_f2['Year'] == 2023, 'hpi_2022'] = 1\n",
    "\n",
    "# Scale the market value by .8 for building and 1/ratio for 2022 value\n",
    "pc_opa_f2 = pc_opa_f2.assign(bld_mv_2022=round(.8*pc_opa_f2['market_value']\n",
    "                             /pc_opa_f2['hpi_2022']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "73879c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:39:03.665043Z",
     "start_time": "2023-08-28T18:39:03.615569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map basements column to basement types\n",
    "# 0. None – Indicates no basement.\n",
    "# A. Full Finished – Occupies the entire area under the first floor.\n",
    "# B. Full Semi-Finished – Could have some finish to include a floor covering,\n",
    "# and ceiling. It looks more like a living area rather than a basement.\n",
    "# C. Full Unfinished – Is a typical basement with unfinished concrete floor,\n",
    "# either rubble stone or cement over stone or concrete walls and would have\n",
    "# exposed wood joist ceilings.\n",
    "# D. Full – Unknown Finish\n",
    "# E. Partial Finished – Occupies a portion under the first floor. Be careful of\n",
    "# areas under sheds and porches. If there is a garage at basement level then it is a\n",
    "# partial basement.\n",
    "# F. Partial Semi-Finished – One or more finished areas.\n",
    "# G. Partial Unfinished\n",
    "# H. Partial - Unknown Finish\n",
    "# I. Unknown Size - Finished\n",
    "# J. Unknown Size - Unfinished\n",
    "\n",
    "# From my property.phila.gov, google maps, opa data groundtruth checks,\n",
    "# each example of null in opa data matches no basement in property.phila.gov\n",
    "# and seems visually plausible. So, fill na with 0 which corresponds to\n",
    "# no basement\n",
    "# The categories w/ letters should be marked as basements\n",
    "# There is no way to know which of the no basement homes are crawl\n",
    "# space homes versus slab or other type of foundation\n",
    "# Further, it's unclear if some crawl space homes may be considered\n",
    "# partial basements. It doesn't appear like this is the case, but\n",
    "# it's uncertain. The way I'm going to do this, na cells become no basement\n",
    "# and we will split no basement into slab & crawl space foundation types\n",
    "# based on NFIP Poliices foundation type proportions\n",
    "# I have no information on pilings/piers and other raised foundations\n",
    "# so will assume they are not in Philadelphia. This could be wrong but \n",
    "# I don't have other information about this\n",
    "\n",
    "# There are also categories 1, 2, 3, and 4 which have no description\n",
    "# in the metadata. So will treat these as no basement\n",
    "# Searching on property.phila.gov, there is nothing said about\n",
    "# the basement type for the properties I've checked\n",
    "\n",
    "# basement or not columns\n",
    "pc_opa_f2['b_type'] = 'NB'\n",
    "# if basements not 0 or null, 'WB'\n",
    "pc_opa_f2.loc[(pc_opa_f2['basements'].notnull()) &\n",
    "              ~(pc_opa_f2['basements'].isin(['0', '1', '2', '3', '4'])),\n",
    "              'b_type'] = 'WB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "41365410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:39:03.793464Z",
     "start_time": "2023-08-28T18:39:03.666542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop any columns that won't be used post merge\n",
    "drop_cols = ['assessment_date', 'Year', 'hpi_2022']\n",
    "pc_opa_m = pc_opa_f2.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ceb78289",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:14:20.757299Z",
     "start_time": "2023-08-28T18:14:19.478558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jumbo/keller-lab/Applications/miniconda3/envs/icom_risk/lib/python3.10/site-packages/geopandas/geodataframe.py:1443: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Footprints: 544977\n",
      "Number of Footprints with w/ unique parcel ids: 494979\n",
      "Number of PWD parcels: 546883\n",
      "Number of PWD parcels w/ unique parcel ids: 546883\n",
      "Number of PWD Parcel/Footprint Matches: 544081\n",
      "Number of PWD Parcel/Footprint Matches w/ unique parcel ids: 494966\n"
     ]
    }
   ],
   "source": [
    "# In bld_fp, get PARCELID column from PARCEL_ID_NUM \n",
    "# as int for merge with pc_pwd['PARCELID']\n",
    "# Drop bld_fp without a PARCEL_ID_NUM\n",
    "bld_fp_m = bld_fp[bld_fp['PARCEL_ID_NUM'].notnull()]\n",
    "# PARCEL_ID_NUM that are not ints cannot be matched\n",
    "# to pc_pwd, so it's ok to treat these as na\n",
    "# The lowest PARCELID is 1, so fillna(0) is fine\n",
    "bld_fp_m['PARCELID'] = pd.to_numeric(bld_fp_m['PARCEL_ID_NUM'],\n",
    "                                     errors='coerce').fillna(0).astype(int)\n",
    "bld_fp_m = bld_fp_m.drop(columns=['PARCEL_ID_NUM'])\n",
    "\n",
    "# Drop geometry for pc_pwd\n",
    "pc_pwd_m = pc_pwd.drop(columns=['geometry'])\n",
    "\n",
    "# Number of footprints\n",
    "print('Number of Footprints: ' \n",
    "      + str(len(bld_fp)))\n",
    "print('Number of Footprints with w/ unique parcel ids: ' \n",
    "      + str(len(bld_fp_m['PARCELID'].unique())))\n",
    "# Number of parcels\n",
    "print('Number of PWD parcels: ' \n",
    "      + str(len(pc_pwd)))\n",
    "print('Number of PWD parcels w/ unique parcel ids: ' \n",
    "      + str(len(pc_pwd['PARCELID'].unique())))\n",
    "\n",
    "# Inner is fine because there is no way to handle\n",
    "# geolocation for flood zones and flood depths\n",
    "# without the building footprints\n",
    "pc_bld = bld_fp_m.merge(pc_pwd_m,\n",
    "                        on=['PARCELID'],\n",
    "                        suffixes=('_bld', '_pc'),\n",
    "                        how='inner')\n",
    "\n",
    "# Number of merged parcel/footprints\n",
    "print('Number of PWD Parcel/Footprint Matches: ' \n",
    "      + str(len(pc_bld)))\n",
    "print('Number of PWD Parcel/Footprint Matches w/ unique parcel ids: ' \n",
    "      + str(len(pc_bld['PARCELID'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2fa9221c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T18:15:32.424226Z",
     "start_time": "2023-08-28T18:15:30.378431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PWD Parcel/Footprint Matches w/ unique parcel ids: 494504\n",
      "Number of OPA Parcels w/ unique parcel ids: 435389\n",
      "Number of PWD/Bld/OPA Parcels w/ unique parcel ids: 395760\n",
      "Number of PWD/Bld/OPA Parcels: 417838\n"
     ]
    }
   ],
   "source": [
    "# Merge resultant gdf by PIN/pin with opa\n",
    "# Check how results compare to merging on brt and parcel_number\n",
    "# I checked BRT_ID (convert to int) and parcel_number\n",
    "# against PIN and pin. I got the same results for # of resultant\n",
    "# rows, and unique ids in the resultant df\n",
    "# I'll use PIN and pin since they are the same dtype\n",
    "# and column name (besides case sensitivity)\n",
    "\n",
    "# Only keep properties with a match. Remainder are ambiguous\n",
    "# Instructed by OPA that PWD and condo matching will be mostly\n",
    "# unsuccessful with these methods. Condos may need more attention later\n",
    "# Discrepancies in loss estimates may be due to ambiguous processing \n",
    "# decisions about which buildings to include and how to estimate losses\n",
    "# for them. An important point may be that reporting absolute losses\n",
    "# is so sensitive to an uncertain extensive margin that it should not\n",
    "# be done without explicitly reporting how many properties are ambiguous\n",
    "# property types\n",
    "\n",
    "pc_bld_f = pc_bld.merge(pc_opa_m,\n",
    "                        left_on=['PIN'],\n",
    "                        right_on=['pin'],\n",
    "                        how='inner')\n",
    "\n",
    "print('Number of PWD Parcel/Footprint Matches w/ unique parcel ids: ' \n",
    "      + str(len(pc_bld['PIN'].unique())))\n",
    "print('Number of OPA Parcels w/ unique parcel ids: ' \n",
    "      + str(len(pc_opa_m['pin'].unique())))\n",
    "print('Number of PWD/Bld/OPA Parcels w/ unique parcel ids: ' \n",
    "      + str(len(pc_bld_f['pin'].unique())))\n",
    "print('Number of PWD/Bld/OPA Parcels: ' \n",
    "      + str(len(pc_bld_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b512143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate results of merge and determine which building_code_description\n",
    "# parcels to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31644d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out building footprint centroids for parcel ids\n",
    "# Some parcels have multiple buildings on them (these are tax parcels)\n",
    "# and we want to have unique ids for these\n",
    "\n",
    "# Write out the unique ids as .pqt with relevant columns for loss estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match pc_pwd and pc_opa on PIN\n",
    "# The PARCELID column in the resulting dataset\n",
    "# can be used to link to PARCEL_ID_ in bld_fp\n",
    "# This avoids relying on potentially inaccurate spatial joins\n",
    "# since we only have point data for opa parcels and \n",
    "# footprint data for buildings\n",
    "# TODO: The more general processing step is for\n",
    "# parcel polygon and building footprint joins. Not all \n",
    "# future sources of appraiser data will provide the links\n",
    "# like the Philadelphia data from PWD. For best performance in our\n",
    "# case-study, it makes sense to use the pre-specified links\n",
    "# of PWD parcels to building footprints. It would be valuable\n",
    "# to benchmark different spatial joining approaches of \n",
    "# PWD parcels and footprints to guide best practices for\n",
    "# these kinds of joins for data that doesn't have pre specified links\n",
    "# This will be the most common use case since building footprint data\n",
    "# is rarely made available from the municipality and often comes\n",
    "# from an external source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b8690",
   "metadata": {},
   "source": [
    "## Process data for uncertainty distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15463d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NFIP Policies to get foundation type proportions by \n",
    "# SFHA/out and pre/post FIRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eee30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NFIP Policies to get # stories proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare NSI structure values to sales values\n",
    "# We can do average NSI value against average HPI adjusted .8*sales value\n",
    "# at the block group level. Take the standard deviation of that\n",
    "# and use it to get a heuristic value for standard deviation\n",
    "# for NSI structure values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d599c",
   "metadata": {},
   "source": [
    "# Link properties to spatial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd96b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T17:28:51.784301Z",
     "start_time": "2023-08-23T17:28:50.808926Z"
    }
   },
   "outputs": [],
   "source": [
    "# NSI and appraiser datasets have building footprint spatial references\n",
    "# We will use these, and their unique ids, to link the structure\n",
    "# inventories to spatial data like flood zones, depth grids, \n",
    "# reference data, and tabular data (which often can be made through shared\n",
    "# references like zip codes or census tracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c9c04",
   "metadata": {},
   "source": [
    "## Hazard data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44500fc",
   "metadata": {},
   "source": [
    "## Reference data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b900919a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:51:39.014509Z",
     "start_time": "2023-08-22T21:51:38.327848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop the following columns\n",
    "drop_cols = ['type', 'geometry.type', 'geometry.coordinates', 'index_right']\n",
    "nsi_gdf = nsi_gdf.drop(columns=drop_cols)\n",
    "\n",
    "# Remove \"properties\" from columns\n",
    "col_updates = [x.replace(\"properties.\", \"\") for x in nsi_gdf.columns]\n",
    "nsi_gdf.columns = col_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7061423c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-22T21:54:55.507123Z",
     "start_time": "2023-08-22T21:52:50.150285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write the NSI data to interim\n",
    "nsi_gdf.to_file(join(EXP_DIR_I, 'nsi.gpkg'), driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1551244d",
   "metadata": {},
   "source": [
    "## Depth Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a92d05",
   "metadata": {},
   "source": [
    "# Prepare depth-damage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e00469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icom_risk",
   "language": "python",
   "name": "icom_risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "322.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
